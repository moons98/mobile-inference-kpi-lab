{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Baseline KPI Analysis\n",
    "\n",
    "This notebook analyzes baseline KPI measurements from different execution paths:\n",
    "- NPU-only\n",
    "- NPU + Fallback\n",
    "- GPU-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from parse_logs import load_log, split_events, calculate_metrics, find_steady_state\n",
    "from plot_kpi import setup_style, plot_kpi_dashboard, plot_latency_histogram\n",
    "\n",
    "setup_style()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "Place your CSV log files in `../data/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('../data')\n",
    "\n",
    "# List available log files\n",
    "log_files = list(DATA_DIR.glob('*.csv'))\n",
    "print(f\"Found {len(log_files)} log files:\")\n",
    "for f in log_files:\n",
    "    print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a single log file for analysis\n",
    "# Replace with your actual file name\n",
    "LOG_FILE = DATA_DIR / 'kpi_log_example.csv'\n",
    "\n",
    "if LOG_FILE.exists():\n",
    "    df = load_log(str(LOG_FILE))\n",
    "    print(f\"Loaded {len(df)} records\")\n",
    "    print(f\"Duration: {df['elapsed_seconds'].max() / 60:.1f} minutes\")\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into inference and system events\n",
    "inference_df, system_df = split_events(df)\n",
    "\n",
    "print(f\"Inference events: {len(inference_df)}\")\n",
    "print(f\"System events: {len(system_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "metrics = calculate_metrics(df)\n",
    "\n",
    "print(\"=\" * 40)\n",
    "print(\"KPI SUMMARY\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"\\nLatency:\")\n",
    "print(f\"  P50: {metrics.latency_p50:.2f} ms\")\n",
    "print(f\"  P95: {metrics.latency_p95:.2f} ms\")\n",
    "print(f\"  Mean: {metrics.latency_mean:.2f} ms (±{metrics.latency_std:.2f})\")\n",
    "print(f\"  Range: [{metrics.latency_min:.2f}, {metrics.latency_max:.2f}] ms\")\n",
    "print(f\"  Count: {metrics.inference_count}\")\n",
    "\n",
    "print(f\"\\nThermal:\")\n",
    "print(f\"  Start: {metrics.thermal_start:.1f} °C\")\n",
    "print(f\"  End: {metrics.thermal_end:.1f} °C\")\n",
    "print(f\"  Max: {metrics.thermal_max:.1f} °C\")\n",
    "print(f\"  Slope: {metrics.thermal_slope:.3f} °C/min\")\n",
    "\n",
    "print(f\"\\nPower:\")\n",
    "print(f\"  Mean: {metrics.power_mean:.1f} mW (±{metrics.power_std:.1f})\")\n",
    "\n",
    "print(f\"\\nMemory:\")\n",
    "print(f\"  Peak: {metrics.memory_peak} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full dashboard\n",
    "fig, axes = plot_kpi_dashboard(df, title=\"Baseline KPI Dashboard\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latency distribution detail\n",
    "fig, ax = plot_latency_histogram(df, title=\"Latency Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Steady-State Analysis\n",
    "\n",
    "Exclude warm-up period and analyze steady-state behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract steady-state (after 30 seconds)\n",
    "steady_df = find_steady_state(df, warm_up_seconds=30.0)\n",
    "steady_metrics = calculate_metrics(steady_df)\n",
    "\n",
    "print(\"Steady-State Metrics (after 30s warm-up):\")\n",
    "print(f\"  Latency P50: {steady_metrics.latency_p50:.2f} ms\")\n",
    "print(f\"  Latency P95: {steady_metrics.latency_p95:.2f} ms\")\n",
    "print(f\"  Power Mean: {steady_metrics.power_mean:.1f} mW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Foreground vs Background (if applicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have background data\n",
    "fg_df = df[df['is_foreground'] == True]\n",
    "bg_df = df[df['is_foreground'] == False]\n",
    "\n",
    "print(f\"Foreground records: {len(fg_df)}\")\n",
    "print(f\"Background records: {len(bg_df)}\")\n",
    "\n",
    "if len(bg_df) > 0:\n",
    "    fg_metrics = calculate_metrics(fg_df)\n",
    "    bg_metrics = calculate_metrics(bg_df)\n",
    "    \n",
    "    print(f\"\\nForeground Latency P50: {fg_metrics.latency_p50:.2f} ms\")\n",
    "    print(f\"Background Latency P50: {bg_metrics.latency_p50:.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary DataFrame\n",
    "summary = pd.DataFrame([{\n",
    "    'latency_p50': metrics.latency_p50,\n",
    "    'latency_p95': metrics.latency_p95,\n",
    "    'latency_mean': metrics.latency_mean,\n",
    "    'latency_std': metrics.latency_std,\n",
    "    'thermal_slope': metrics.thermal_slope,\n",
    "    'thermal_max': metrics.thermal_max,\n",
    "    'power_mean': metrics.power_mean,\n",
    "    'memory_peak': metrics.memory_peak,\n",
    "    'inference_count': metrics.inference_count,\n",
    "    'duration_seconds': metrics.duration_seconds\n",
    "}])\n",
    "\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
